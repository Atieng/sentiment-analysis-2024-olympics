{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Paris Olympics is a global sporting event that has garnered significant attention and engagement across various social media platforms. Analyzing public sentiment regarding the Olympics can provide valuable insights into how athletes, countries and the overall event are perceived. This analysis can benefit sports organizations, media outlets, sponsors offering feedback on public perception, performance and engagement levels thus helping to tailor content and marketing strategies. Sentiment analysis can also benefit city officials to improve planning and address concerns such as health and sanitation.\n",
    "The goal of this project is to perform a comprehensive sentiment analysis of social media content related to this year's Paris Olympics to understand public sentiment, identify emerging trends and provide a comprehensive understanding of how different aspects of the Olympics resonate with audiences worldwide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Paris Olympics is a high-profile event that generates a substantial volume of unstructured social media data that reflects public sentiment. The challenge lies in effectively analyzing this vast and diverse stream of data while also tackling challenges such as language differences, sentiment variations and contextual meanings in order to provide accurate and actionable insights. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proposed Solutions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\tUse API access to collect data from major social media platforms and ensure compliance with platform policies and data protection regulations.\n",
    "2.\tImplement text normalization, tokenization and content filtering while utilizing language detection and translation tools for multilingual data handling. \n",
    "3.\tEmploy advanced natural language processing models like BERT or GPT for sentiment classification incorporating sarcasm detection and contextual analysis for improved accuracy. \n",
    "4.\tCreate an interactive dashboard using Tableau to display sentiment trends and insights with features for data filtering and exploring different aspects of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Objective\n",
    "Develop a comprehensive social media sentiment analysis model that accurately captures and interprets public sentiment about the Paris Olympics from social media data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specific Objectives\n",
    "1.\tTo extract, preprocess and clean social media data from multiple platforms addressing quality issues and handling multilingual content related to the Paris Olympics. \n",
    "2.\tTo develop and train advanced natural language processing models to accurately classify sentiments incorporating techniques to handle sarcasm and contextual nuances. \n",
    "3.\tTo create interactive visualizations to display sentiment trends and key events providing actionable insights to stakeholders based on comprehensive analysis of public opinions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Success Metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Accuracy – The proportion of correctly classified sentiments (positive, negative, neutral) out of all sentiments predicted by the model.\n",
    "85% - 90%\n",
    "\n",
    "- Precision -  The proportion of true positive sentiment predictions (correctly identified positive tweets) out of all predicted positives.\n",
    "80% - 90% for both positive and negative sentiment classes.\n",
    "75% - 85% for the neutral class.\n",
    "\n",
    "- Recall - The proportion of true positive sentiment predictions out of all actual positives.\n",
    "75% - 80% for all sentiment classes.\n",
    "\n",
    "- F1 Score - The harmonic mean of Precision and Recall that provides a single metric that balances both precision and recall.\n",
    "0.75 to 0.85\n",
    "\n",
    "- Area Under the Curve - Receiver Operating Characteristic (AUC-ROC) - Measures how well a model distinguishes between classes. > 0.85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenges\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Social media data is noisy and unstructured presenting challenges for accurate analysis. \n",
    "- Distinguishing between positive, negative and neutral sentiments can be difficult especially when dealing with multilingual content thus affecting sentiment analysis accuracy\n",
    "- The volume of social media posts and comments can be overwhelming particularly during major events like the Olympics. Managing and processing large volumes of real-time data necessitates efficient data handling and processing techniques. \n",
    "- Interpreting context and sarcasm an extra layer of complexity as the sentiment expressed may not always align with the literal meaning of the words used. Social media content often includes informal language, slang and nuanced expressions that can skew sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sentiment analysis project aims to deliver a comprehensive understanding of public opinion about the Paris Olympics by leveraging social media data. By addressing the challenges of data quality, sentiment accuracy, multilingual content and implementing advanced NLP techniques, the project will provide actionable insights to the aforementioned stakeholders. Successful execution will enable better engagement strategies and enhance the overall experience of the Olympics for audiences worldwide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA UNDERSTANDING\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Sources\n",
    "1.\tAPIs - Extract data from social media sites such as Twitter, Facebook and Instagram in the form of posts, tweets, comments and hashtags using their respective APIs. \n",
    "The focus will be on posts mentioning Paris Olympics, relevant hashtags and location-based data.\n",
    "\n",
    "2.\tWeb Scraping - Extract additional data from comments and discussions from news sites and sports forums such as ESPN and Sports Center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\tSocial media data in the form of tweets, facebook and Instagram posts and comments mentioning the Paris Olympics.\n",
    "2.\tNews articles, comments and replies discussing the various aspects of the Olympics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relevance of The Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">The data sources and datasets identified for this project are highly relevant to analyzing public sentiment surrounding the Paris Olympics. Social media platforms like Twitter, Facebook and Instagram capture immediate reactions, discussions and emotional responses from a global audience thus providing a rich source of unfiltered public sentiment. \n",
    "The inclusion of location-based data and relevant hashtags allows for more targeted analysis potentially revealing geographical trends and topic-specific sentiments. Complementing this with web scraping of news sites and sports forums like ESPN and Sports Center adds depth to the analysis by incorporating more structured discussions and content.\n",
    "This combination of data sources offers a comprehensive view of public sentiment ranging from spontaneous reactions on social media to more considered opinions in news comment sections and sports forums."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python Modules Importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary modules\n",
    "# manupulation\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2600 entries, 0 to 2599\n",
      "Data columns (total 18 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   id             2600 non-null   int64 \n",
      " 1   tweetText      2600 non-null   object\n",
      " 2   tweetURL       2600 non-null   object\n",
      " 3   type           2600 non-null   object\n",
      " 4   tweetAuthor    2600 non-null   object\n",
      " 5   handle         2600 non-null   object\n",
      " 6   geo            1573 non-null   object\n",
      " 7   mentions       1177 non-null   object\n",
      " 8   hashtags       1024 non-null   object\n",
      " 9   replyCount     2600 non-null   int64 \n",
      " 10  quoteCount     2600 non-null   int64 \n",
      " 11  retweetCount   2600 non-null   int64 \n",
      " 12  likeCount      2600 non-null   int64 \n",
      " 13  views          2600 non-null   object\n",
      " 14  bookmarkCount  2600 non-null   int64 \n",
      " 15  createdAt      2600 non-null   object\n",
      " 16  allMediaURL    578 non-null    object\n",
      " 17  videoURL       136 non-null    object\n",
      "dtypes: int64(6), object(12)\n",
      "memory usage: 365.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Folder in which the csv files are found\n",
    "folder_path = 'X_data'\n",
    "\n",
    "# List of all the csv files found in the folder\n",
    "csv_files = [fil for fil in os.listdir(folder_path) if fil.endswith('.csv')]\n",
    "\n",
    "# Create an empty list to store DataFrames\n",
    "data_frames = []\n",
    "\n",
    "# Loop through the list of CSV files and read each one into a DataFrame\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    data_frames.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into one (stack vertically)\n",
    "merged_df = pd.concat(data_frames, ignore_index=True, sort=False)\n",
    "\n",
    "merged_df.info()\n",
    "\n",
    "# Save the concatenated DataFrame to a new CSV file\n",
    "new_df = '2024-olympics-sentiments.csv'\n",
    "merged_df.to_csv(new_df, index=False)\n",
    "# print(f'merged CSV file saved as {output_file}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class DataUnderstanding():\n",
    "    \"\"\"Class that provides an understanding of a dataset\"\"\"\n",
    "    \n",
    "    def __init__(self, data=None):\n",
    "        \"\"\"Initialization\"\"\"\n",
    "        self.df = data\n",
    "\n",
    "    def load_data(self, path):\n",
    "        \"\"\"Load the data\"\"\"\n",
    "        if self.df is None:\n",
    "            self.df = pd.read_csv(path, encoding='latin-1')\n",
    "        return self.df\n",
    "\n",
    "    def understanding(self):\n",
    "        \"\"\"Provides insights into the dataset\"\"\"\n",
    "        # Info\n",
    "        print(\"INFO\")\n",
    "        print(\"-\" * 4)\n",
    "        self.df.info()\n",
    "\n",
    "        # Shape\n",
    "        print(\"\\n\\nSHAPE\")\n",
    "        print(\"-\" * 5)\n",
    "        print(f\"Records in dataset: {self.df.shape[0]} with {self.df.shape[1]} columns.\")\n",
    "\n",
    "        # Columns\n",
    "        print(\"\\n\\nCOLUMNS\")\n",
    "        print(\"-\" * 6)\n",
    "        print(\"Columns in the dataset are:\")\n",
    "        for idx in self.df.columns:\n",
    "            print(f\"- {idx}\")\n",
    "\n",
    "        # Unique Values\n",
    "        print(\"\\n\\nUNIQUE VALUES\")\n",
    "        print(\"-\" * 12)\n",
    "        for col in self.df.columns:\n",
    "            print(f\"Column {col} has {self.df[col].nunique()} unique values\")\n",
    "            if self.df[col].nunique() < 12:\n",
    "                print(f\"Top unique values in {col} include:\")\n",
    "                for idx in self.df[col].value_counts().index:\n",
    "                    print(f\"- {idx}\")\n",
    "            print(\"\")\n",
    "\n",
    "        # Missing or Null Values\n",
    "        print(\"\\nMISSING VALUES\")\n",
    "        print(\"-\" * 15)\n",
    "        for col in self.df.columns:\n",
    "            print(f\"Column {col} has {self.df[col].isnull().sum()} missing values.\")\n",
    "\n",
    "        # Duplicate Values\n",
    "        print(\"\\n\\nDUPLICATE VALUES\")\n",
    "        print(\"-\" * 16)\n",
    "        print(f\"The dataset has {self.df.duplicated().sum()} duplicated records.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    id                                          tweetText  \\\n",
      "0  1820934767312859634  Kellie Harrington homecoming after Tokyo 2020 ...   \n",
      "1  1820934764871794856  ÎÎµ ÏÏÎ¿Ï Î¤ÎÎÎÎÎ©Î£ÎÎ¤Î Î¼ÏÎ®ÎºÎµ ...   \n",
      "2  1820934747964559415  @PopBase #Olympics USA is good but will be beaten   \n",
      "3  1820934747280859532  ÎÎµ ÏÏÎ¿Ï Î¤ÎÎÎÎÎ©Î£ÎÎ¤Î Î¼ÏÎ®ÎºÎµ ...   \n",
      "4  1820934736237199545  #Olympics Women's semi-final:\\r\\nBrazil are fl...   \n",
      "\n",
      "                                            tweetURL   type  \\\n",
      "0  https://x.com/HonestFrank/status/1820934767312...  tweet   \n",
      "1  https://x.com/WaltersPa4652/status/18209347648...  tweet   \n",
      "2  https://x.com/JayGaran/status/1820934747964559415  tweet   \n",
      "3  https://x.com/WaltersPa4652/status/18209347472...  tweet   \n",
      "4  https://x.com/BabaGol_/status/1820934736237199545  tweet   \n",
      "\n",
      "                  tweetAuthor          handle             geo  mentions  \\\n",
      "0               Francis Keogh    @HonestFrank             NaN       NaN   \n",
      "1            Paulette Walters  @WaltersPa4652             NaN       NaN   \n",
      "2  Jay Garan ð°ðªð°ðª       @JayGaran  Mombasa, Kenya  @PopBase   \n",
      "3            Paulette Walters  @WaltersPa4652             NaN       NaN   \n",
      "4                     BabaGol       @BabaGol_             NaN       NaN   \n",
      "\n",
      "                                        hashtags  replyCount  quoteCount  \\\n",
      "0                              #Olympics,#boxing           0           0   \n",
      "1  #TeamHellas,#paris2024,#Olympics,#paris2024gr           0           0   \n",
      "2                                      #Olympics           0           0   \n",
      "3  #TeamHellas,#paris2024,#Olympics,#paris2024gr           0           0   \n",
      "4                                      #Olympics           0           0   \n",
      "\n",
      "   retweetCount  likeCount views  bookmarkCount            createdAt  \\\n",
      "0             0          0     -              0  2024-08-07 00:27:34   \n",
      "1             0          0     -              0  2024-08-07 00:27:33   \n",
      "2             0          0     -              0  2024-08-07 00:27:29   \n",
      "3             0          0     -              0  2024-08-07 00:27:29   \n",
      "4             0          0     -              0  2024-08-07 00:27:27   \n",
      "\n",
      "                                         allMediaURL  \\\n",
      "0    https://pbs.twimg.com/media/E8dKeTiWQAAdJVN.jpg   \n",
      "1                                                NaN   \n",
      "2                                                NaN   \n",
      "3                                                NaN   \n",
      "4  https://pbs.twimg.com/media/GUVCeZMXEAAjpsA.jp...   \n",
      "\n",
      "                                            videoURL  \n",
      "0  https://video.twimg.com/amplify_video/14251889...  \n",
      "1                                                NaN  \n",
      "2                                                NaN  \n",
      "3                                                NaN  \n",
      "4                                                NaN  \n",
      "INFO\n",
      "----\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2600 entries, 0 to 2599\n",
      "Data columns (total 18 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   id             2600 non-null   int64 \n",
      " 1   tweetText      2600 non-null   object\n",
      " 2   tweetURL       2600 non-null   object\n",
      " 3   type           2600 non-null   object\n",
      " 4   tweetAuthor    2600 non-null   object\n",
      " 5   handle         2600 non-null   object\n",
      " 6   geo            1573 non-null   object\n",
      " 7   mentions       1177 non-null   object\n",
      " 8   hashtags       1024 non-null   object\n",
      " 9   replyCount     2600 non-null   int64 \n",
      " 10  quoteCount     2600 non-null   int64 \n",
      " 11  retweetCount   2600 non-null   int64 \n",
      " 12  likeCount      2600 non-null   int64 \n",
      " 13  views          2600 non-null   object\n",
      " 14  bookmarkCount  2600 non-null   int64 \n",
      " 15  createdAt      2600 non-null   object\n",
      " 16  allMediaURL    578 non-null    object\n",
      " 17  videoURL       136 non-null    object\n",
      "dtypes: int64(6), object(12)\n",
      "memory usage: 365.8+ KB\n",
      "\n",
      "\n",
      "SHAPE\n",
      "-----\n",
      "Records in dataset: 2600 with 18 columns.\n",
      "\n",
      "\n",
      "COLUMNS\n",
      "------\n",
      "Columns in the dataset are:\n",
      "- id\n",
      "- tweetText\n",
      "- tweetURL\n",
      "- type\n",
      "- tweetAuthor\n",
      "- handle\n",
      "- geo\n",
      "- mentions\n",
      "- hashtags\n",
      "- replyCount\n",
      "- quoteCount\n",
      "- retweetCount\n",
      "- likeCount\n",
      "- views\n",
      "- bookmarkCount\n",
      "- createdAt\n",
      "- allMediaURL\n",
      "- videoURL\n",
      "\n",
      "\n",
      "UNIQUE VALUES\n",
      "------------\n",
      "Column id has 2600 unique values\n",
      "\n",
      "Column tweetText has 2472 unique values\n",
      "\n",
      "Column tweetURL has 2600 unique values\n",
      "\n",
      "Column type has 1 unique values\n",
      "Top unique values in type include:\n",
      "- tweet\n",
      "\n",
      "Column tweetAuthor has 2206 unique values\n",
      "\n",
      "Column handle has 2223 unique values\n",
      "\n",
      "Column geo has 1036 unique values\n",
      "\n",
      "Column mentions has 869 unique values\n",
      "\n",
      "Column hashtags has 590 unique values\n",
      "\n",
      "Column replyCount has 24 unique values\n",
      "\n",
      "Column quoteCount has 11 unique values\n",
      "Top unique values in quoteCount include:\n",
      "- 0\n",
      "- 1\n",
      "- 2\n",
      "- 3\n",
      "- 5\n",
      "- 4\n",
      "- 9\n",
      "- 16\n",
      "- 14\n",
      "- 8\n",
      "- 6\n",
      "\n",
      "Column retweetCount has 30 unique values\n",
      "\n",
      "Column likeCount has 70 unique values\n",
      "\n",
      "Column views has 470 unique values\n",
      "\n",
      "Column bookmarkCount has 13 unique values\n",
      "\n",
      "Column createdAt has 1037 unique values\n",
      "\n",
      "Column allMediaURL has 577 unique values\n",
      "\n",
      "Column videoURL has 136 unique values\n",
      "\n",
      "\n",
      "MISSING VALUES\n",
      "---------------\n",
      "Column id has 0 missing values.\n",
      "Column tweetText has 0 missing values.\n",
      "Column tweetURL has 0 missing values.\n",
      "Column type has 0 missing values.\n",
      "Column tweetAuthor has 0 missing values.\n",
      "Column handle has 0 missing values.\n",
      "Column geo has 1027 missing values.\n",
      "Column mentions has 1423 missing values.\n",
      "Column hashtags has 1576 missing values.\n",
      "Column replyCount has 0 missing values.\n",
      "Column quoteCount has 0 missing values.\n",
      "Column retweetCount has 0 missing values.\n",
      "Column likeCount has 0 missing values.\n",
      "Column views has 0 missing values.\n",
      "Column bookmarkCount has 0 missing values.\n",
      "Column createdAt has 0 missing values.\n",
      "Column allMediaURL has 2022 missing values.\n",
      "Column videoURL has 2464 missing values.\n",
      "\n",
      "\n",
      "DUPLICATE VALUES\n",
      "----------------\n",
      "The dataset has 0 duplicated records.\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of DataUnderstanding\n",
    "data = DataUnderstanding()\n",
    "\n",
    "# Load the dataset\n",
    "df = data.load_data(path=\"merged_file.csv\")\n",
    "\n",
    "# Display the first five rows of the dataset\n",
    "print(df.head())\n",
    "\n",
    "# Get an understanding of the dataset\n",
    "data.understanding()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\n",
      "----\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2600 entries, 0 to 2599\n",
      "Data columns (total 18 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   id             2600 non-null   int64 \n",
      " 1   tweetText      2600 non-null   object\n",
      " 2   tweetURL       2600 non-null   object\n",
      " 3   type           2600 non-null   object\n",
      " 4   tweetAuthor    2600 non-null   object\n",
      " 5   handle         2600 non-null   object\n",
      " 6   geo            1573 non-null   object\n",
      " 7   mentions       1177 non-null   object\n",
      " 8   hashtags       1024 non-null   object\n",
      " 9   replyCount     2600 non-null   int64 \n",
      " 10  quoteCount     2600 non-null   int64 \n",
      " 11  retweetCount   2600 non-null   int64 \n",
      " 12  likeCount      2600 non-null   int64 \n",
      " 13  views          2600 non-null   object\n",
      " 14  bookmarkCount  2600 non-null   int64 \n",
      " 15  createdAt      2600 non-null   object\n",
      " 16  allMediaURL    578 non-null    object\n",
      " 17  videoURL       136 non-null    object\n",
      "dtypes: int64(6), object(12)\n",
      "memory usage: 365.8+ KB\n",
      "\n",
      "\n",
      "SHAPE\n",
      "-----\n",
      "Records in dataset: 2600 with 18 columns.\n",
      "\n",
      "\n",
      "COLUMNS\n",
      "------\n",
      "Columns in the dataset are:\n",
      "- id\n",
      "- tweetText\n",
      "- tweetURL\n",
      "- type\n",
      "- tweetAuthor\n",
      "- handle\n",
      "- geo\n",
      "- mentions\n",
      "- hashtags\n",
      "- replyCount\n",
      "- quoteCount\n",
      "- retweetCount\n",
      "- likeCount\n",
      "- views\n",
      "- bookmarkCount\n",
      "- createdAt\n",
      "- allMediaURL\n",
      "- videoURL\n",
      "\n",
      "\n",
      "UNIQUE VALUES\n",
      "------------\n",
      "Column id has 2600 unique values\n",
      "\n",
      "Column tweetText has 2472 unique values\n",
      "\n",
      "Column tweetURL has 2600 unique values\n",
      "\n",
      "Column type has 1 unique values\n",
      "Top unique values in type include:\n",
      "- tweet\n",
      "\n",
      "Column tweetAuthor has 2206 unique values\n",
      "\n",
      "Column handle has 2223 unique values\n",
      "\n",
      "Column geo has 1036 unique values\n",
      "\n",
      "Column mentions has 869 unique values\n",
      "\n",
      "Column hashtags has 590 unique values\n",
      "\n",
      "Column replyCount has 24 unique values\n",
      "\n",
      "Column quoteCount has 11 unique values\n",
      "Top unique values in quoteCount include:\n",
      "- 0\n",
      "- 1\n",
      "- 2\n",
      "- 3\n",
      "- 5\n",
      "- 4\n",
      "- 9\n",
      "- 16\n",
      "- 14\n",
      "- 8\n",
      "- 6\n",
      "\n",
      "Column retweetCount has 30 unique values\n",
      "\n",
      "Column likeCount has 70 unique values\n",
      "\n",
      "Column views has 470 unique values\n",
      "\n",
      "Column bookmarkCount has 13 unique values\n",
      "\n",
      "Column createdAt has 1037 unique values\n",
      "\n",
      "Column allMediaURL has 577 unique values\n",
      "\n",
      "Column videoURL has 136 unique values\n",
      "\n",
      "\n",
      "MISSING VALUES\n",
      "---------------\n",
      "Column id has 0 missing values.\n",
      "Column tweetText has 0 missing values.\n",
      "Column tweetURL has 0 missing values.\n",
      "Column type has 0 missing values.\n",
      "Column tweetAuthor has 0 missing values.\n",
      "Column handle has 0 missing values.\n",
      "Column geo has 1027 missing values.\n",
      "Column mentions has 1423 missing values.\n",
      "Column hashtags has 1576 missing values.\n",
      "Column replyCount has 0 missing values.\n",
      "Column quoteCount has 0 missing values.\n",
      "Column retweetCount has 0 missing values.\n",
      "Column likeCount has 0 missing values.\n",
      "Column views has 0 missing values.\n",
      "Column bookmarkCount has 0 missing values.\n",
      "Column createdAt has 0 missing values.\n",
      "Column allMediaURL has 2022 missing values.\n",
      "Column videoURL has 2464 missing values.\n",
      "\n",
      "\n",
      "DUPLICATE VALUES\n",
      "----------------\n",
      "The dataset has 0 duplicated records.\n",
      "Dropping rows with null values\n",
      "Dropping columns: ['videoURL', 'allMediaURL', 'hashtags', 'mentions', 'geo']\n",
      "                       id                                          tweetText  \\\n",
      "220   1821157503683502193  #VineshPhogat Disqualified\\r\\n\\r\\n\"This is a s...   \n",
      "234   1821157377128693786  @MagnumPio_2 @matiofubol Tweet muto #Olympics ...   \n",
      "244   1821157280672542897  ..\"à¤¸à¥à¤®à¤¿à¤«à¤¾à¤à¤¨à¤² à¤à¥à¤²à¤¨à¥...   \n",
      "255   1821157164792102914  #VineshPhogat Disqualified\\r\\n\\r\\n\"When wrestl...   \n",
      "261   1821157013113438303  @Jerry_DurhamPT Yea it's not right. Should be ...   \n",
      "435   1820940695693115538  Il y a encore un mois, ils ne sâÃ©taient jam...   \n",
      "1137  1819160649944956962  The Olympics' inclusion of mixed-gender combat...   \n",
      "1793  1821478195343868280  Wales Flyers Fun Day jumps into action! @Wales...   \n",
      "1858  1821478093451608575  Racisme anti-Blanches Ã  #Paris2024 : devinez ...   \n",
      "1932  1821477968218120465  #Paris2024| Olympic medalist #ManuBhaker meets...   \n",
      "2402  1821477083475751350  quel combat ðð²ð¹ð¶ð",
      " ðððð...   \n",
      "\n",
      "                                               tweetURL   type  \\\n",
      "220   https://x.com/MirrorNow/status/182115750368350...  tweet   \n",
      "234    https://x.com/1marcoo/status/1821157377128693786  tweet   \n",
      "244     https://x.com/aajtak/status/1821157280672542897  tweet   \n",
      "255   https://x.com/MirrorNow/status/182115716479210...  tweet   \n",
      "261   https://x.com/DavidPTDPT/status/18211570131134...  tweet   \n",
      "435   https://x.com/FranceTV/status/1820940695693115538  tweet   \n",
      "1137  https://x.com/stevegrubershow/status/181916064...  tweet   \n",
      "1793  https://x.com/waleshighnews/status/18214781953...  tweet   \n",
      "1858  https://x.com/BonneDroite/status/1821478093451...  tweet   \n",
      "1932   https://x.com/LokPoll/status/1821477968218120465  tweet   \n",
      "2402  https://x.com/KarineGuguen/status/182147708347...  tweet   \n",
      "\n",
      "                         tweetAuthor            handle  replyCount  \\\n",
      "220                       Mirror Now        @MirrorNow           0   \n",
      "234        marcotraversi â¨ðºð¦          @1marcoo           1   \n",
      "244                           AajTak           @aajtak           0   \n",
      "255                       Mirror Now        @MirrorNow           0   \n",
      "261         David Friedberg, PT, DPT       @DavidPTDPT           0   \n",
      "435                        France tv         @FranceTV           0   \n",
      "1137                    Steve Gruber  @stevegrubershow           5   \n",
      "1793                 Wales High News    @waleshighnews           0   \n",
      "1858       Une Bonne Droite ðð»      @BonneDroite           1   \n",
      "1932                        Lok Poll          @LokPoll           0   \n",
      "2402  Karine Guguen ð«ð·ðªðº     @KarineGuguen           0   \n",
      "\n",
      "      quoteCount  retweetCount  likeCount views  bookmarkCount  \\\n",
      "220            0             0          0     8              0   \n",
      "234            0             0          0     9              0   \n",
      "244            0             0         10   265              0   \n",
      "255            0             0          0    41              1   \n",
      "261            0             0          0    12              0   \n",
      "435            0             0          0     3              0   \n",
      "1137           0             7         24  1168              1   \n",
      "1793           0             0          0     4              0   \n",
      "1858           0             0         12   125              0   \n",
      "1932           0             1         10   335              0   \n",
      "2402           0             0          0    47              0   \n",
      "\n",
      "               createdAt  \n",
      "220  2024-08-07 15:12:39  \n",
      "234  2024-08-07 15:12:08  \n",
      "244  2024-08-07 15:11:45  \n",
      "255  2024-08-07 15:11:18  \n",
      "261  2024-08-07 15:10:42  \n",
      "435  2024-08-07 00:51:07  \n",
      "1137 2024-08-02 02:57:51  \n",
      "1793 2024-08-08 12:26:57  \n",
      "1858 2024-08-08 12:26:33  \n",
      "1932 2024-08-08 12:26:03  \n",
      "2402 2024-08-08 12:22:32  \n"
     ]
    }
   ],
   "source": [
    " \n",
    "class DataCleaning(DataUnderstanding):\n",
    "    \"\"\"This class is used for data cleaning\"\"\"\n",
    "    \n",
    "    def drop_columns(self, columns):\n",
    "        \"\"\"Drop specified columns\"\"\"\n",
    "        print(f\"Dropping columns: {columns}\")\n",
    "        self.df.drop(columns=columns, inplace=True)\n",
    "\n",
    "    def remove_duplicates(self):\n",
    "        \"\"\"Remove duplicates\"\"\"\n",
    "        print(\"Removing duplicates\")\n",
    "        self.df.drop_duplicates(inplace=True)\n",
    "\n",
    "    def drop_nulls(self):\n",
    "        \"\"\"Drop rows with any null values\"\"\"\n",
    "        print(\"Dropping rows with null values\")\n",
    "        self.df.dropna(inplace=True)\n",
    "\n",
    "#     def rename_columns(self, columns_dict):\n",
    "#         \"\"\"Rename columns based on the provided dictionary\"\"\"\n",
    "#         print(f\"Renaming columns: {columns_dict}\")\n",
    "#         self.df.rename(columns=columns_dict, inplace=True)\n",
    "        \n",
    "    def strip_column_names(self):\n",
    "        \"\"\"Strip whitespace from column names\"\"\"\n",
    "        print(\"Stripping whitespace from column names\")\n",
    "        self.df.columns = self.df.columns.str.strip()\n",
    "        \n",
    "    \n",
    "     \n",
    "    def convert_to_datetime(self, column_name):\n",
    "        \"\"\"Convert a column to datetime format\"\"\"\n",
    "        self.df[column_name] = pd.to_datetime(self.df[column_name])\n",
    "\n",
    "    def filter_year(self, column_name, year):\n",
    "        \"\"\"Filter rows based on a specific year\"\"\"\n",
    "        self.df = self.df[self.df[column_name].dt.year == year]\n",
    "\n",
    "\n",
    "# Example Usage:\n",
    "\n",
    "# Load data and understand it\n",
    "understanding = DataCleaning()\n",
    "\n",
    "# Load the data (replace with your actual file path)\n",
    "data_path = 'merged_file.csv'\n",
    "df = understanding.load_data(data_path)\n",
    "\n",
    "# Get an overview of the data\n",
    "understanding.understanding()\n",
    "\n",
    "# Perform data cleaning\n",
    "understanding.drop_nulls()  # Drop rows with null values\n",
    "understanding.drop_columns(['videoURL','allMediaURL','hashtags','mentions','geo'])  # Drop unnecessary columns\n",
    "understanding.convert_to_datetime('createdAt')       # Convert 'createdAt' to datetime\n",
    "understanding.filter_year('createdAt', 2024) \n",
    "\n",
    "# Print the cleaned DataFrame\n",
    "print(understanding.df)\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
